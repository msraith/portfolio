# -*- coding: utf-8 -*-
"""Spark_2_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y6oS7jkBO9ZIDcFp3IfcgTcYCJQkWpSG
"""

from pyspark.sql.functions import col
from pyspark.sql.functions import lag
from pyspark.sql.window import Window

df = (spark.read.option('header', True)
  .option('sep',',')
  .option('inferSchema', True)
  .csv('owid-covid-data.csv'))

windowSpec = Window
  .partitionBy('location') 
  .orderBy('date')

df.select('iso_code','location','date', 'new_cases')
    .where(col('location').startswith('Russia'))
    .withColumn('lag_day_case',lag('new_cases',1).over(windowSpec))
    .where((col('date')>"2021-03-23")&(col('date')<="2021-03-31"))
    .withColumn('delta',col('new_cases')-col('lag_day_case')
    )
  .show()